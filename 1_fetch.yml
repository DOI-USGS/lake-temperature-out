target_default: 1_fetch

packages:
  - sbtools
  - readr
  - jsonlite

sources:
  - 1_fetch/src/fetch_sb_item_files.R
  - 1_fetch/src/copy_caldera_files.R

targets:
  1_fetch:
    depends:
    # mntoha data release targets
      - 1_fetch/out/lake_metadata.csv
      - 1_fetch/out/config.json
      - 1_fetch/out/irradiance_downloaded.yml
      - 1_fetch/out/pb0_temp_pred_downloaded.yml
      - 1_fetch/out/clarity_downloaded.yml
      - 1_fetch/out/iceflags_downloaded.yml
      - 1_fetch/out/glm2_lake_metadata.csv
    # multi-state glm2 data release targets
      - 1_fetch/out/glm2_pb0_config.json
      - 1_fetch/out/glm2_pball_config.json
      - 1_fetch/out/glm2_pb0_pball_temp_pred_downloaded.yml
      - 1_fetch/out/glm2_iceflags_downloaded.yml
    # error estimation temp data targets
      - 1_fetch/out/temperature_observations.zip
      - 1_fetch/out/pb0_matched_to_observations.zip
      - 1_fetch/out/pgdl_matched_to_observations.zip
    # climate projections glm3 data release target
      - 1_fetch/out/pb0_temp_projections.yml
      - 1_fetch/out/pb0_temp_projections_nml.rds.ind
  
  sb_dl_date:
   command: c(I("2021-04-08"))
  
  ##-- Download files for mntoha data release --##
  
  toha_sbid:
    command: c(I("5e5d0bb9e4b01d50924f2b36"))
  clarity_ice_sbid:
    command: c(I("5e5d0b96e4b01d50924f2b34"))
  
  1_fetch/out/lake_metadata.csv:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5e5c1c1ce4b01d50924f27e7"), 
      sb_filename = I('lake_metadata.csv'),
      dummy = sb_dl_date)
  
  1_fetch/out/config.json:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5e5c1c36e4b01d50924f27ea"), 
      sb_filename = I('pb0_config.json'),
      dummy = sb_dl_date)
  
  1_fetch/out/irradiance_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = toha_sbid, 
      keyword = I("irradiance"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date)
  
  1_fetch/out/pgdl_temp_pred_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = toha_sbid, 
      keyword = I("pgdl_predictions"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date)
      
  1_fetch/out/pb0_temp_pred_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = toha_sbid, 
      keyword = I("pb0_predictions"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date)
      
  1_fetch/out/clarity_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = clarity_ice_sbid, 
      keyword = I("clarity"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date)
  
  1_fetch/out/iceflags_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = clarity_ice_sbid, 
      keyword = I("ice_flags"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date)
  
  ##-- Download files for multi-state glm2 data release --##
  
  1_fetch/out/glm2_lake_metadata.csv:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5db8194be4b0b0c58b5a4c3c"), 
      sb_filename = I('01_lake_metadata.csv'),
      dummy = sb_dl_date)
  
  glm2_config_sbid:
    command: c(I("5db81967e4b0b0c58b5a4c3f"))
  
  1_fetch/out/glm2_pb0_config.json:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = glm2_config_sbid, 
      sb_filename = I('pb0_config.json'),
      dummy = sb_dl_date)
  
  1_fetch/out/glm2_pball_config.json:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = glm2_config_sbid, 
      sb_filename = I('pball_config.json'),
      dummy = sb_dl_date)
  
  # Add prefix to multi-file downloads in case previous 
  #  pb0 ones (from mntoha release) are named the same
  
  # This contains PB0 GLM2 and PBALL data in each zip.
  1_fetch/out/glm2_pb0_pball_temp_pred_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = I("5db819a8e4b0b0c58b5a4c45"), 
      keyword = I("predictions"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date,
      dest_file_prefix = I("glm2"))
  
  1_fetch/out/glm2_iceflags_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = I("5db81996e4b0b0c58b5a4c43"), 
      keyword = I("ice_flags"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date,
      dest_file_prefix = I("glm2"))
  
  ##-- Download files for error estimation --##
  
  # All observed temperature data is in one
  # CSV file that is zipped up
  1_fetch/out/temperature_observations.zip:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5e5d0b68e4b01d50924f2b32"), 
      sb_filename = I("temperature_observations.zip"),
      dummy = sb_dl_date)
  
  # PB0 temp data matched to obs depths and dates
  1_fetch/out/pb0_matched_to_observations.zip:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5e774324e4b01d509270e29f"), 
      sb_filename = I("pb0_matched_to_observations.zip"),
      dummy = sb_dl_date)
  
  # PGDL temp data matched to obs depths and dates
  1_fetch/out/pgdl_matched_to_observations.zip:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5e774324e4b01d509270e29f"), 
      sb_filename = I("pgdl_matched_to_observations.zip"),
      dummy = sb_dl_date)
  
  ##-- Access files for GLM3 + GCM projections data release --##
  
  caldera_access_date:
    command: c(I('2022-02-16'))
  
  # These files from our process-models pipeline are also pushed to ScienceBase
  #   item `6206d3c2d34ec05caca53071` but since we are running this on Tallgrass
  #   we have access to Caldera and can skip the need to re-download.
  pb0_temp_projections_feathers:
    command: list.files(
      path = I('../lake-temperature-process-models/3_extract/out'), 
      pattern = I('GLM_nhdhr_(.*)(GFDL|IPSL|MIROC5|MRI|ACCESS|CNRM).feather'), 
      full.names = I(TRUE))
    depends: 
      - caldera_access_date
  1_fetch/out/pb0_temp_projections.yml:
    command: sc_indicate(target_name, data_file = pb0_temp_projections_feathers)
    depends: 
      - caldera_access_date
  
  # These files from our process-models pipeline are also pushed to ScienceBase
  #   item `6206d3c2d34ec05caca53071` but since we are running this on Tallgrass
  #   we have access to Caldera and can skip the need to re-download.
  1_fetch/out/pb0_temp_projections_nml.rds.ind:
    command: copy_caldera_files(target_name, files_in = I('../lake-temperature-process-models/1_prep/in/nml_list.rds'))
    depends: 
      - caldera_access_date
    
