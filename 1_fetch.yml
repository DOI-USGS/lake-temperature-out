target_default: 1_fetch

packages:
  - sbtools
  - readr
  - jsonlite

sources:
  - 1_fetch/src/fetch_sb_item_files.R
  - 1_fetch/src/fetch_caldera_file_helpers.R

targets:
  1_fetch:
    depends:
    # mntoha data release targets
      - 1_fetch/out/lake_metadata.csv
      - 1_fetch/out/config.json
      - 1_fetch/out/irradiance_downloaded.yml
      - 1_fetch/out/pb0_temp_pred_downloaded.yml
      - 1_fetch/out/clarity_downloaded.yml
      - 1_fetch/out/iceflags_downloaded.yml
      - 1_fetch/out/glm2_lake_metadata.csv
    # multi-state glm2 data release targets
      - 1_fetch/out/glm2_pb0_config.json
      - 1_fetch/out/glm2_pball_config.json
      - 1_fetch/out/glm2_pb0_pball_temp_pred_downloaded.yml
      - 1_fetch/out/glm2_iceflags_downloaded.yml
    # error estimation temp data targets
      - 1_fetch/out/temperature_observations.zip
      - 1_fetch/out/pb0_matched_to_observations.zip
      - 1_fetch/out/pgdl_matched_to_observations.zip
    # glm3 climate projections & glm3 nldas targets
      - 1_fetch/out/glm3_pb0gcm_temp_files.yml
      - 1_fetch/out/glm3_pb0nldas_temp_files.yml
      - 1_fetch/out/nml_list.rds.ind
  
  sb_dl_date:
   command: c(I("2021-04-08"))
  
  ##-- Download files for mntoha data release --##
  
  toha_sbid:
    command: c(I("5e5d0bb9e4b01d50924f2b36"))
  clarity_ice_sbid:
    command: c(I("5e5d0b96e4b01d50924f2b34"))
  
  1_fetch/out/lake_metadata.csv:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5e5c1c1ce4b01d50924f27e7"), 
      sb_filename = I('lake_metadata.csv'),
      dummy = sb_dl_date)
  
  1_fetch/out/config.json:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5e5c1c36e4b01d50924f27ea"), 
      sb_filename = I('pb0_config.json'),
      dummy = sb_dl_date)
  
  1_fetch/out/irradiance_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = toha_sbid, 
      keyword = I("irradiance"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date)
  
  1_fetch/out/pgdl_temp_pred_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = toha_sbid, 
      keyword = I("pgdl_predictions"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date)
      
  1_fetch/out/pb0_temp_pred_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = toha_sbid, 
      keyword = I("pb0_predictions"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date)
      
  1_fetch/out/clarity_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = clarity_ice_sbid, 
      keyword = I("clarity"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date)
  
  1_fetch/out/iceflags_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = clarity_ice_sbid, 
      keyword = I("ice_flags"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date)
  
  ##-- Download files for multi-state glm2 data release --##
  
  1_fetch/out/glm2_lake_metadata.csv:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5db8194be4b0b0c58b5a4c3c"), 
      sb_filename = I('01_lake_metadata.csv'),
      dummy = sb_dl_date)
  
  glm2_config_sbid:
    command: c(I("5db81967e4b0b0c58b5a4c3f"))
  
  1_fetch/out/glm2_pb0_config.json:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = glm2_config_sbid, 
      sb_filename = I('pb0_config.json'),
      dummy = sb_dl_date)
  
  1_fetch/out/glm2_pball_config.json:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = glm2_config_sbid, 
      sb_filename = I('pball_config.json'),
      dummy = sb_dl_date)
  
  # Add prefix to multi-file downloads in case previous 
  #  pb0 ones (from mntoha release) are named the same
  
  # This contains PB0 GLM2 and PBALL data in each zip.
  1_fetch/out/glm2_pb0_pball_temp_pred_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = I("5db819a8e4b0b0c58b5a4c45"), 
      keyword = I("predictions"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date,
      dest_file_prefix = I("glm2"))
  
  1_fetch/out/glm2_iceflags_downloaded.yml:
    command: download_sb_files(
      target_name = target_name, 
      sb_id = I("5db81996e4b0b0c58b5a4c43"), 
      keyword = I("ice_flags"), 
      dest_folder = I("1_fetch/tmp"),
      dummy = sb_dl_date,
      dest_file_prefix = I("glm2"))
  
  ##-- Download files for error estimation --##
  
  # All observed temperature data is in one
  # CSV file that is zipped up
  1_fetch/out/temperature_observations.zip:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5e5d0b68e4b01d50924f2b32"), 
      sb_filename = I("temperature_observations.zip"),
      dummy = sb_dl_date)
  
  # PB0 temp data matched to obs depths and dates
  1_fetch/out/pb0_matched_to_observations.zip:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5e774324e4b01d509270e29f"), 
      sb_filename = I("pb0_matched_to_observations.zip"),
      dummy = sb_dl_date)
  
  # PGDL temp data matched to obs depths and dates
  1_fetch/out/pgdl_matched_to_observations.zip:
    command: download_sb_single_file(
      target_name = target_name,
      sb_id = I("5e774324e4b01d509270e29f"), 
      sb_filename = I("pgdl_matched_to_observations.zip"),
      dummy = sb_dl_date)
  
  ##-- Access files for GLM3 + GCM projections data release --##
  
  # TODO: Switch to downloading the NetCDF file(s) from ScienceBase
  # to use as input instead. That would be less brittle.
  
  # Identifying what lakes / GLM temp output files to use to for 
  # lake thermal metrics summaries depends on us changing this 
  # date to refresh the list of files and hashes. Not the most
  # ideal process, but the function + practicality of this approach
  # is a bit of a compromise right now so we can complete this work.
  caldera_access_date_nml:
    command: c(I('2022-06-01'))
  caldera_access_date_gcm:
    command: c(I('2022-06-01'))
  caldera_access_date_nldas:
    command: c(I('2022-06-01'))
  
  # These files from our process-models pipeline are also pushed to ScienceBase
  #   item `6206d3c2d34ec05caca53071` but since we are running this on Tallgrass
  #   we have access to Caldera and can skip the need to re-download.
  # This NML file is shared between the GCMs and NLDAS runs.
  1_fetch/out/nml_list.rds.ind:
    command: copy_caldera_files(target_name, files_in = I('../lake-temperature-process-models/1_prep/in/nml_list.rds'))
    depends: 
      - caldera_access_date_nml
  
  # These files from our process-models pipeline are also pushed to ScienceBase
  #   item `6206d3c2d34ec05caca53071` but since we are running this on Tallgrass
  #   we have access to Caldera and can skip the need to re-download.
  glm3_pb0gcm_temp_file_regex:
    command: c(I('(GLM)_(nhdhr_.*)_(GFDL|IPSL|MIROC5|MRI|ACCESS|CNRM).feather'))
  glm3_pb0gcm_temp_file_regex_grp_nms:
    command: c(I('prefix'), I('site_id'), I('GCM'))
  1_fetch/out/glm3_pb0gcm_temp_files.yml:
    command: extract_glm_files(
      target_name, 
      glm_run_output_file = I('../lake-temperature-process-models/3_extract/out/GLM_GCM_summary.csv'))
    depends: 
      - caldera_access_date_gcm
  
  glm3_pb0nldas_temp_file_regex:
    command: c(I('(GLM)_(nhdhr_.*)_(NLDAS).feather'))
  glm3_pb0nldas_temp_file_regex_grp_nms:
    command: c(I('prefix'), I('site_id'), I('driver'))
  1_fetch/out/glm3_pb0nldas_temp_files.yml:
    command: extract_glm_files(
      target_name, 
      glm_run_output_file = I('../lake-temperature-process-models/3_extract/out/GLM_NLDAS_summary.csv'))
    depends: 
      - caldera_access_date_nldas
