target_default: 2_process

packages:
  - arrow
  - dplyr
  - tidyr
  - scipiper
  - readr
  - purrr

sources:
  - 2_process/src/process_helpers.R
  - 2_process/src/do_lakegroup_tasks.R
  - 2_process/src/do_lake_toha_tasks.R
  - 2_process/src/observed_data_helpers_prepare.R
  - 2_process/src/do_obs_lakes_tasks.R
  - 2_process/src/do_split_morph_tasks.R

targets:
  2_process:
    depends:
    # mntoha data release targets
      - 2_process/out/2_pb0_lake_tasks.ind
      - 2_process/out/2_pgdl_lake_tasks.ind
      - 2_process/out/iceflags_unzipped.yml
    # multi-state glm2 data release targets
      - 2_process/out/2_glm2_pb0_unzipped.yml
      - 2_process/out/2_glm2_pball_unzipped.yml
      - 2_process/out/glm2_iceflags_unzipped.yml
    # error estimation temp data targets
      - 2_process/out/combined_obs_toha.csv
    # 2022 runs
      - 2_process/out/split_morph_files.ind
  
##-- MN TOHA Data Release --##
  
  sb_group_info:
    command: read_csv("1_fetch/out/lake_metadata.csv")
  sb_group_ids:
    command: get_group_ids(sb_group_info)
    
  morphometry:
    command: extract_morphometry("1_fetch/out/config.json")
  
  ### Munge data by each lake group ###
  
  # Unzip each lake group file, then merge and write feather files for each lake
  
  2_process/out/2_pgdl_grp_tasks_completed.yml:
    command: do_lakegroup_tasks(
      final_target =  target_name,
      task_ids = sb_group_ids,
      irradiance_zips = '1_fetch/out/irradiance_downloaded.yml', 
      clarity_zips = '1_fetch/out/clarity_downloaded.yml', 
      predictions_zips = '1_fetch/out/pgdl_temp_pred_downloaded.yml',
      '2_process/src/munge_group_files.R',
      '2_process/src/do_lakegroup_tasks.R')
  
  2_process/out/2_pb0_grp_tasks_completed.yml:
    command: do_lakegroup_tasks(
      final_target =  target_name,
      task_ids = sb_group_ids,
      irradiance_zips = '1_fetch/out/irradiance_downloaded.yml', 
      clarity_zips = '1_fetch/out/clarity_downloaded.yml', 
      predictions_zips = '1_fetch/out/pb0_temp_pred_downloaded.yml',
      '2_process/src/munge_group_files.R',
      '2_process/src/do_lakegroup_tasks.R')
  
  ### Calculate TOHA for each lake ###
  
  2_process/out/2_pb0_lake_tasks.ind:
    command: do_lake_toha_tasks(
      final_target = target_name,
      task_df_fn = '2_process/out/2_pb0_grp_tasks_completed.yml',
      n_cores = 40,
      '2_process/src/calculate_toha.R',
      '2_process/src/do_lake_toha_tasks.R')
    depends:
      - morphometry

  2_process/out/2_pgdl_lake_tasks.ind:
    command: do_lake_toha_tasks(
      final_target = target_name,
      task_df_fn = '2_process/out/2_pgdl_grp_tasks_completed.yml',
      n_cores = 40,
      '2_process/src/calculate_toha.R',
      '2_process/src/do_lake_toha_tasks.R')
    depends:
      - morphometry

  ### Prepare ice flags for use in 3_summary ###
  
  2_process/out/iceflags_unzipped.yml:
    command: unzip_data(
      target_name = target_name,
      data_file = "1_fetch/out/iceflags_downloaded.yml",
      out_dir = I("2_process/tmp"))
  
##-- Multi-state GLM2 Data Release --##
  
  glm2_sb_group_info:
    command: read_csv("1_fetch/out/glm2_lake_metadata.csv")
  glm2_sb_group_ids:
    command: get_group_ids(glm2_sb_group_info)
    
  glm2_pb0_morphometry:
    command: extract_morphometry("1_fetch/out/glm2_pb0_config.json")  
  glm2_pball_morphometry:
    command: extract_morphometry("1_fetch/out/glm2_pball_config.json")
  
  ### Munge data by each lake group ###
  
  # Unzip each lake group file, then subset into a yml for pb0 and one for pball
  
  2_process/out/2_glm2_pb0_pball_unzipped.yml:
    command: unzip_data(
      target_name = target_name,
      data_file = "1_fetch/out/glm2_pb0_pball_temp_pred_downloaded.yml",
      out_dir = I("2_process/tmp_glm2"))
      
  2_process/out/2_glm2_pb0_unzipped.yml:
    command: subset_yml(
      target_name = target_name,
      full_yml = "2_process/out/2_glm2_pb0_pball_unzipped.yml",
      regex = I("pb0_"))
  
  2_process/out/2_glm2_pball_unzipped.yml:
    command: subset_yml(
      target_name = target_name,
      full_yml = "2_process/out/2_glm2_pb0_pball_unzipped.yml",
      regex = I("pball_"))
  
  # Prepare ice flags for use in 3_summary. Contains pb0 and pball 
  # ice flags, but those are handled in 3_summarize with the regex.
  2_process/out/glm2_iceflags_unzipped.yml:
    command: unzip_data(
      target_name = target_name,
      data_file = "1_fetch/out/glm2_iceflags_downloaded.yml",
      out_dir = I("2_process/tmp"))
      
##-- Munge files for error estimation --##

  ### Calculate TOHA for each lake using observed temperature data ###
  
  ## Prepare irradiance and clarity data for merging with observed temp by unzipping individual lake files ##
  2_process/out/irradiance_unzipped.yml:
    command: unzip_data(
      target_name = target_name,
      data_file = "1_fetch/out/irradiance_downloaded.yml",
      out_dir = I("2_process/tmp"))
  2_process/out/clarity_unzipped.yml:
    command: unzip_data(
      target_name = target_name,
      data_file = "1_fetch/out/clarity_downloaded.yml",
      out_dir = I("2_process/tmp"))
  
  ## Split observed data into one file per lake ##
  2_process/out/observed_temperatures_split.yml:
    command: unzip_and_split_observed_data(
      target_name = target_name,
      obs_zipfile = "1_fetch/out/temperature_observations.zip",
      split_file_prefix = I("2_process/tmp/split_obs_data"))
  
  2_process/out/combined_obs_toha.csv:
    command: do_obs_lake_tasks(
      target_name = target_name,
      task_df_fn = '2_process/out/observed_temperatures_split.yml', 
      irr_df_fn = '2_process/out/irradiance_unzipped.yml',
      k0_df_fn = '2_process/out/clarity_unzipped.yml',
      obs_model = I('obs'),
      "2_process/src/observed_data_helpers_munge.R", 
      "2_process/src/calculate_toha.R",
      "2_process/src/do_obs_lakes_tasks.R")
    depends:
      - morphometry
  
  ### Now calculate TOHA for PB0 matched to observed ###
  
  ## Split data into one file per lake ##
  2_process/out/pb0_matched2obs_split.yml:
    command: unzip_and_split_observed_data(
      target_name = target_name,
      obs_zipfile = "1_fetch/out/pb0_matched_to_observations.zip",
      split_file_prefix = I("2_process/tmp/split_pb0_matched2obs_data"))
  
  2_process/out/combined_pb0_matched2obs_toha.csv:
    command: do_obs_lake_tasks(
      target_name = target_name,
      task_df_fn = '2_process/out/pb0_matched2obs_split.yml', 
      irr_df_fn = '2_process/out/irradiance_unzipped.yml',
      k0_df_fn = '2_process/out/clarity_unzipped.yml',
      obs_model = I('pb0_matched2obs'),
      "2_process/src/observed_data_helpers_munge.R", 
      "2_process/src/calculate_toha.R",
      "2_process/src/do_obs_lakes_tasks.R")
    depends:
      - morphometry
  
  ### Now calculate TOHA for PGDL matched to observed ###
  
  ## Split data into one file per lake ##
  2_process/out/pgdl_matched2obs_split.yml:
    command: unzip_and_split_observed_data(
      target_name = target_name,
      obs_zipfile = "1_fetch/out/pgdl_matched_to_observations.zip",
      split_file_prefix = I("2_process/tmp/split_pgdl_matched2obs_data"))
  
  2_process/out/combined_pgdl_matched2obs_toha.csv:
    command: do_obs_lake_tasks(
      target_name = target_name,
      task_df_fn = '2_process/out/pgdl_matched2obs_split.yml', 
      irr_df_fn = '2_process/out/irradiance_unzipped.yml',
      k0_df_fn = '2_process/out/clarity_unzipped.yml',
      obs_model = I('pgdl_matched2obs'),
      "2_process/src/observed_data_helpers_munge.R", 
      "2_process/src/calculate_toha.R",
      "2_process/src/do_obs_lakes_tasks.R")
    depends:
      - morphometry

##-- Munge files for GLM3 + GCM projections + updated NLDAS data release --##

  # Extract valid sites to use for subsetting the NML list
  # First ones are based on the projections but we can combine
  # the NLDAS ones as well, so that we are not duplicating any morph files.
  glm3_pb0gcm_site_ids:
    command: extract_site_ids(
      file_ind = "1_fetch/out/glm3_pb0gcm_temp_files.yml",
      regex = glm3_pb0gcm_temp_file_regex,
      regex_grp_nms = glm3_pb0gcm_temp_file_regex_grp_nms)
  glm3_pb0nldas_site_ids:
    command: c()
  
  # Not much munging required right now
  glm3_nml_morphometry_subset:
    command: nml_to_morphometry_subset(
      in_ind = '1_fetch/out/pb0_temp_projections_nml.rds.ind',
      glm3_pb0gcm_site_ids,
      glm3_pb0nldas_site_ids)
  2_process/out/split_morph_files.ind:
    command: do_split_morph_tasks(
      final_target = target_name,
      dir = I('2_process/morph_files'),
      morphometry = glm3_nml_morphometry_subset,
      n_cores = 60,
      '2_process/src/do_split_morph_tasks.R',
      '3_summarize/src/do_annual_thermal_metric_tasks.R')
  
